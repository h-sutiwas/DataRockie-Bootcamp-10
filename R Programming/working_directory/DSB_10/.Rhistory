## easy to create data pipelines [df %>% select() %>% filter() %>% mutate() %>% arrange()]
head(imdb)
imdb %>%
select(movie_name = MOVIE_NAME, release_year = YEAR) %>%
head()
imdb %>%
select(MOVIE_NAME, RATING)
## filter data
filter(imdb, SCORE >= 9.0)
imdb %>% filter(SCORE >= 9.0)
names(imdb) <- tolower(names(imdb))
imdb %>%
select(movie_name, year, score) %>%
filter(score >= 9.0 & year > 2000)
imdb %>%
select(movie_name, year, score) %>%
filter(score == 8.8 | score == 8.3 | score == 9.0)
imdb %>%
select(movie_name, year, score) %>%
filter(score %in% c(8.3, 8.8, 9.0))
## filter string columns
# grepl("Drama", imdb$genre) help find "Drama" within genre string columns
# while ignoring their position or if said movie have other genre type inside their string.
imdb %>%
select(movie_name, genre, rating) %>%
filter(rating == "PG-13")
imdb %>%
select(movie_name, genre, rating) %>%
filter(grepl("Drama", imdb$genre))
imdb %>%
select(movie_name) %>%
filter(grepl("King", imdb$movie_name))
# case sensitive with all lowercase "king"
## arrange data
head(imdb)
imdb %>%
arrange(length) %>%
head(10)
imdb %>%
arrange(desc(length)) %>% ## descending order
head(10)
imdb %>%
arrange(rating, desc(length))
## create new columns
imdb %>%
select(movie_name, score, length) %>%
mutate(score_group = if_else(score >= 9, "High Rating", "Low Rating"),
length_group = if_else(length >= 120, "Long Film", "Short Film"))
imdb %>%
select(movie_name, score) %>%
mutate(score = score + 0.1) %>%
head(10)
## summarize and group by
# summarise(name_stat = stat_func())
# summarise stat groups by rating types
imdb %>%
filter(rating != "") %>%
group_by(rating) %>%
summarise(mean_length = mean(length),
sd_length = sd(length),
min_length = min(length),
max_length = max(length),
n = n()
)
## join data
favorite_films <- data.frame(id = c(5, 10, 25, 30, 98))
favorite_films %>%
inner_join(imdb, by = c("id" = "no"))
# --- Join table favorite_films with imdb by column "id"   ##
##              inside favorite_films with column "no" ---  #
## write csv file (export result)
imdb_prep <- imdb %>%
select(movie_name, released_year = year, rating, length, score) %>%
filter(rating == "R" & released_year > 2000)
## export csv file
write.csv(imdb_prep, "imdb_prep.csv", row.names = FALSE)
save.image()
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(RSQLite)
library(glue)
library(RPostgreSQL)
library(lubridate)
library(sqldf)
# library glue -> to glue messages
my_name <- "toy"
my_age <- 35
glue("Hi my name is {my_name}. Today I'm {my_age} years old.")
# library tidyverse
# data transformation => dplyr
# 1. select
# 2. filter
# 3. arrange
# 4. mutate => create new column
# 5. summarise
mtcars <- rownames_to_column(mtcars, "model")
view(mtcars)
# pipeline
select(mtcars, mpg, hp, wt)
m2 <- mtcars %>%
select(mpg, hp, wt) %>%
filter(hp > 200) %>%
arrange(mpg) %>%
head()
head(arrange(filter(select(mtcars, mpg, hp, wt), hp > 200), mpg))
# filter am == 0
# grep can return character value and normally return the index of said value
# but grepl() will always return logic value
mtcars %>%
select(model, mpg, hp, wt, am) %>%
filter(am == 0 & grepl("^M", model)) %>%
arrange(am, desc(hp))
m3 <- mtcars %>%
select(model, mpg, hp, wt, am) %>%
filter(between(hp, 100, 200)) %>%
arrange(am, desc(hp))
# write csv file
write_csv(m3, "result.csv")
# mutate to create new columns
mtcars %>%
filter(mpg >= 20) %>%
select(model, mpg, hp, wt, am) %>%
mutate(new_col = "Data Rockie",
hp_halve = hp/2,
## =IF(am==0,"auto", "manual")
am_label = if_else(am==0,"auto", "manual"))
# summarise, summarize
# aggregate function in SQL
m4 <- mtcars %>%
mutate(am = if_else(am==0, "auto", "manual")) %>%
group_by(am) %>%
summarise(avg_mpg = mean(mpg),
med_mpg = median(mpg),
sum_mpg = sum(mpg),
max_mpg = max(mpg),
max_hp = max(hp),
min_hp = min(hp),
# spread
n = n(),
# var_hp = var(hp),
# sd_hp = sd(hp)
)
write_csv(m4, "sum_m4.csv")
## join in R
left_join(band_members, band_instruments, by = "name")
inner_join(band_members, band_instruments, by = "name")
full_join(band_members, band_instruments, by = "name")
m5 <- band_members %>%
select(member_name = name,
band_name = band) %>%
left_join(band_instruments,
by = c("member_name" = "name"))
## random sampling
# pull() pull column values only in a vector
mtcars %>%
sample_n(5) %>%
pull(model)
mtcars %>%
# sample_frac(0.20) %>%
summarise(avg_hp = mean(hp))
## summary
## 100% => Analytics
## 20% => Statistics
## count
mtcars <- mtcars %>%
mutate(am = if_else(am==0,
"Auto",
"Manual"))
sqldf("
SELECT
mpg,
hp
FROM mtcars
WHERE hp >= 200")
library("sqldf")
sqldf("
SELECT
mpg,
hp
FROM mtcars
WHERE hp >= 200")
## create connection to sqlite.db file
con <- dbConnect(SQLite(), "C:\Online Learning\DataRockie Bootcamp\DataRockie Bootcamp 10th\R Programming\data\chinook")
## create connection to sqlite.db file
con <- dbConnect(SQLite(), "C:/Online Learning/DataRockie Bootcamp/DataRockie Bootcamp 10th/R Programming/data/chinook/chinook.db")
## list tables
dbListTables(con)
## list fields/ columns
dbListFields(con, "customers")
## get data from database tables
usa <- dbGetQuery(con, "select firstname, email from customers
where country = 'USA' ")
## create dataframe
products <- tribble(
~id, ~product_name,
1, "chocolate",
2, "pineapple",
3, "samsung galaxy s23"
)
## write table to database
dbWriteTable(con, "products", products)
## remove table
dbRemoveTable(con, "products")
## close connection
dbDisconnect(con)
## connect to PostgreSQL server
## create connection to elephantsql.com after building a database
# these parameters below are used as connector
con <- dbConnect(
PostgreSQL(),
host = "arjuna.db.elephantsql.com",
dbname = "hcmsanst",
user = "hcmsanst",
password = "n9MIT1wNqy6HG5HsO-ypvf8SLD4VfMCh",
port = 5432
)
## db List Tables
dbListTables(con)
dbWriteTable(con, "products", products)
## get data
df <- dbGetQuery(con, "select id, product_name from products")
## create connection to sqlite.db file
con <- dbConnect(SQLite(), "C:/Online Learning/DataRockie Bootcamp/DataRockie Bootcamp 10th/R Programming/data/chinook/chinook.db")
## list tables
dbListTables(con)
## list fields/ columns
dbListFields(con, "customers")
## get data from database tables
usa <- dbGetQuery(con, "
select
firstname,
lastname,
country,
email
from customers
where country = 'USA' ")
## create dataframe
products <- tribble(
~id, ~product_name,
1, "chocolate",
2, "pineapple",
3, "samsung galaxy s23"
)
## write table to database
dbWriteTable(con, "products", products)
## remove table
dbRemoveTable(con, "products")
## close connection
dbDisconnect(con)
## create connection to sqlite.db file
con <- dbConnect(SQLite(), "C:/Online Learning/DataRockie Bootcamp/DataRockie Bootcamp 10th/R Programming/data/chinook/chinook.db")
## list tables
dbListTables(con)
## list fields/ columns
dbListFields(con, "customers")
## get data from database tables
usa <- dbGetQuery(con, "
select
firstname,
lastname,
country,
email
from customers
where country = 'USA' ")
## create dataframe
products <- tribble(
~id, ~product_name,
1, "chocolate",
2, "pineapple",
3, "samsung galaxy s23"
)
## write table to database
dbWriteTable(con, "products", products)
## remove table
dbRemoveTable(con, "products")
## close connection
dbDisconnect(con)
usa
## connect to PostgreSQL server
## create connection to elephantsql.com after building a database
# these parameters below are used as connector
con <- dbConnect(
PostgreSQL(),
host = "arjuna.db.elephantsql.com",
dbname = "hcmsanst",
user = "hcmsanst",
password = "n9MIT1wNqy6HG5HsO-ypvf8SLD4VfMCh",
port = 5432
)
## db List Tables
dbListTables(con)
dbWriteTable(con, "products", products)
## get data
df <- dbGetQuery(con, "select id, product_name from products")
{
"name": "ham",
knitr::opts_chunk$set(echo = TRUE)
library(jsonlite)
list.files(pattern="*.json")
list.files(pattern="*.r")
cd
help
getwd()
/..
../..
setwd("C:\Online Learning\DataRockie Bootcamp\DataRockie Bootcamp 10th\R Programming\data)
getwd("C:/Online Learning/DataRockie Bootcamp/DataRockie Bootcamp 10th/R Programming/data)
e
gg
getwwd()
getwd()
break
../..
print("hello")
getwd()
)
getwd()
getwd(~/)
getwd(../data)
getwd(/R Programming/data)
getwd("/R Programming/data")
~/R Programming/data
## how to read a json file
fromJSON("../data/my_profile.json")
## how to read a json file
my_profile <- fromJSON("../data/my_profile.json")
my_profile
# library tidyverse
# data transformation => dplyr
# 1. select
# 2. filter
# 3. arrange
# 4. mutate => create new column
# 5. summarise
carnames <- rownames(mtcars)
mtcars <- rownames_to_column(mtcars, "model")
library(tidyverse)
library(RSQLite)
library(glue)
library(RPostgreSQL)
library(lubridate)
library(sqldf)
library(jsonlite)
# library tidyverse
# data transformation => dplyr
# 1. select
# 2. filter
# 3. arrange
# 4. mutate => create new column
# 5. summarise
carnames <- rownames(mtcars)
mtcars <- rownames_to_column(mtcars, "model")
# library tidyverse
# data transformation => dplyr
# 1. select
# 2. filter
# 3. arrange
# 4. mutate => create new column
# 5. summarise
carnames <- rownames(mtcars)
view(mtcars)
# pipeline
select(mtcars, mpg, hp, wt)
m2 <- mtcars %>%
select(mpg, hp, wt) %>%
filter(hp > 200) %>%
arrange(mpg) %>%
head()
head(arrange(filter(select(mtcars, mpg, hp, wt), hp > 200), mpg))
# filter am == 0
# grep can return character value and normally return the index of said value
# but grepl() will always return logic value
mtcars %>%
select(model, mpg, hp, wt, am) %>%
filter(am == 0 & grepl("^M", model)) %>%
arrange(am, desc(hp))
m3 <- mtcars %>%
select(model, mpg, hp, wt, am) %>%
filter(between(hp, 100, 200)) %>%
arrange(am, desc(hp))
# write csv file
write_csv(m3, "result.csv")
# mutate to create new columns
mtcars %>%
filter(mpg >= 20) %>%
select(model, mpg, hp, wt, am) %>%
mutate(new_col = "Data Rockie",
hp_halve = hp/2,
## =IF(am==0,"auto", "manual")
am_label = if_else(am==0,"auto", "manual"))
# summarise, summarize
# aggregate function in SQL
m4 <- mtcars %>%
mutate(am = if_else(am==0, "auto", "manual")) %>%
group_by(am) %>%
summarise(avg_mpg = mean(mpg),
med_mpg = median(mpg),
sum_mpg = sum(mpg),
max_mpg = max(mpg),
max_hp = max(hp),
min_hp = min(hp),
# spread
n = n(),
# var_hp = var(hp),
# sd_hp = sd(hp)
)
write_csv(m4, "sum_m4.csv")
## join in R
left_join(band_members, band_instruments, by = "name")
inner_join(band_members, band_instruments, by = "name")
full_join(band_members, band_instruments, by = "name")
m5 <- band_members %>%
select(member_name = name,
band_name = band) %>%
left_join(band_instruments,
by = c("member_name" = "name"))
## random sampling
# pull() pull column values only in a vector
mtcars %>%
sample_n(5) %>%
pull(model)
mtcars %>%
# sample_frac(0.20) %>%
summarise(avg_hp = mean(hp))
## summary
## 100% => Analytics
## 20% => Statistics
## count
mtcars <- mtcars %>%
mutate(am = if_else(am==0,
"Auto",
"Manual"))
# library tidyverse
# data transformation => dplyr
# 1. select
# 2. filter
# 3. arrange
# 4. mutate => create new column
# 5. summarise
carnames <- rownames(mtcars)
view(mtcars)
# pipeline
select(mtcars, mpg, hp, wt)
m2 <- mtcars %>%
select(mpg, hp, wt) %>%
filter(hp > 200) %>%
arrange(mpg) %>%
head()
head(arrange(filter(select(mtcars, mpg, hp, wt), hp > 200), mpg))
# filter am == 0
# grep can return character value and normally return the index of said value
# but grepl() will always return logic value
mtcars %>%
select(model, mpg, hp, wt, am) %>%
filter(am == 0 & grepl("^M", model)) %>%
arrange(am, desc(hp))
m3 <- mtcars %>%
select(model, mpg, hp, wt, am) %>%
filter(between(hp, 100, 200)) %>%
arrange(am, desc(hp))
# write csv file
write_csv(m3, "result.csv")
# mutate to create new columns
mtcars %>%
filter(mpg >= 20) %>%
select(model, mpg, hp, wt, am) %>%
mutate(new_col = "Data Rockie",
hp_halve = hp/2,
## =IF(am==0,"auto", "manual")
am_label = if_else(am==0,"auto", "manual"))
# summarise, summarize
# aggregate function in SQL
m4 <- mtcars %>%
mutate(am = if_else(am==0, "auto", "manual")) %>%
group_by(am) %>%
summarise(avg_mpg = mean(mpg),
med_mpg = median(mpg),
sum_mpg = sum(mpg),
max_mpg = max(mpg),
max_hp = max(hp),
min_hp = min(hp),
# spread
n = n(),
# var_hp = var(hp),
# sd_hp = sd(hp)
)
write_csv(m4, "sum_m4.csv")
## join in R
left_join(band_members, band_instruments, by = "name")
inner_join(band_members, band_instruments, by = "name")
full_join(band_members, band_instruments, by = "name")
m5 <- band_members %>%
select(member_name = name,
band_name = band) %>%
left_join(band_instruments,
by = c("member_name" = "name"))
## random sampling
# pull() pull column values only in a vector
mtcars %>%
sample_n(5) %>%
pull(model)
mtcars %>%
# sample_frac(0.20) %>%
summarise(avg_hp = mean(hp))
## summary
## 100% => Analytics
## 20% => Statistics
## count
mtcars <- mtcars %>%
mutate(am = if_else(am==0,
"Auto",
"Manual"))
