# 4. mutate => create new column
# 5. summarise
mtcars <- rownames_to_column(mtcars, "model")
view(mtcars)
# pipeline
select(mtcars, mpg, hp, wt)
m2 <- mtcars %>%
select(mpg, hp, wt) %>%
filter(hp > 200) %>%
arrange(mpg) %>%
head()
head(arrange(filter(select(mtcars, mpg, hp, wt), hp > 200), mpg))
# filter am == 0
# grep can return character value and normally return the index of said value
# but grepl() will always return logic value
mtcars %>%
select(model, mpg, hp, wt, am) %>%
filter(am == 0 & grepl("^M", model)) %>%
arrange(am, desc(hp))
m3 <- mtcars %>%
select(model, mpg, hp, wt, am) %>%
filter(between(hp, 100, 200)) %>%
arrange(am, desc(hp))
# write csv file
write_csv(m3, "result.csv")
# mutate to create new columns
mtcars %>%
filter(mpg >= 20) %>%
select(model, mpg, hp, wt, am) %>%
mutate(new_col = "Data Rockie",
hp_halve = hp/2,
## =IF(am==0,"auto", "manual")
am_label = if_else(am==0,"auto", "manual"))
# summarise, summarize
# aggregate function in SQL
m4 <- mtcars %>%
mutate(am = if_else(am==0, "auto", "manual")) %>%
group_by(am) %>%
summarise(avg_mpg = mean(mpg),
med_mpg = median(mpg),
sum_mpg = sum(mpg),
max_mpg = max(mpg),
max_hp = max(hp),
min_hp = min(hp),
# spread
n = n(),
# var_hp = var(hp),
# sd_hp = sd(hp)
)
write_csv(m4, "sum_m4.csv")
## join in R
left_join(band_members, band_instruments, by = "name")
inner_join(band_members, band_instruments, by = "name")
full_join(band_members, band_instruments, by = "name")
m5 <- band_members %>%
select(member_name = name,
band_name = band) %>%
left_join(band_instruments,
by = c("member_name" = "name"))
## random sampling
# pull() pull column values only in a vector
mtcars %>%
sample_n(5) %>%
pull(model)
mtcars %>%
# sample_frac(0.20) %>%
summarise(avg_hp = mean(hp))
## summary
## 100% => Analytics
## 20% => Statistics
## count
mtcars <- mtcars %>%
mutate(am = if_else(am==0,
"Auto",
"Manual"))
sqldf("
SELECT
mpg,
hp
FROM mtcars
WHERE hp >= 200")
library("sqldf")
sqldf("
SELECT
mpg,
hp
FROM mtcars
WHERE hp >= 200")
## create connection to sqlite.db file
con <- dbConnect(SQLite(), "C:\Online Learning\DataRockie Bootcamp\DataRockie Bootcamp 10th\R Programming\data\chinook")
## create connection to sqlite.db file
con <- dbConnect(SQLite(), "C:/Online Learning/DataRockie Bootcamp/DataRockie Bootcamp 10th/R Programming/data/chinook/chinook.db")
## list tables
dbListTables(con)
## list fields/ columns
dbListFields(con, "customers")
## get data from database tables
usa <- dbGetQuery(con, "select firstname, email from customers
where country = 'USA' ")
## create dataframe
products <- tribble(
~id, ~product_name,
1, "chocolate",
2, "pineapple",
3, "samsung galaxy s23"
)
## write table to database
dbWriteTable(con, "products", products)
## remove table
dbRemoveTable(con, "products")
## close connection
dbDisconnect(con)
## connect to PostgreSQL server
## create connection to elephantsql.com after building a database
# these parameters below are used as connector
con <- dbConnect(
PostgreSQL(),
host = "arjuna.db.elephantsql.com",
dbname = "hcmsanst",
user = "hcmsanst",
password = "n9MIT1wNqy6HG5HsO-ypvf8SLD4VfMCh",
port = 5432
)
## db List Tables
dbListTables(con)
dbWriteTable(con, "products", products)
## get data
df <- dbGetQuery(con, "select id, product_name from products")
## create connection to sqlite.db file
con <- dbConnect(SQLite(), "C:/Online Learning/DataRockie Bootcamp/DataRockie Bootcamp 10th/R Programming/data/chinook/chinook.db")
## list tables
dbListTables(con)
## list fields/ columns
dbListFields(con, "customers")
## get data from database tables
usa <- dbGetQuery(con, "
select
firstname,
lastname,
country,
email
from customers
where country = 'USA' ")
## create dataframe
products <- tribble(
~id, ~product_name,
1, "chocolate",
2, "pineapple",
3, "samsung galaxy s23"
)
## write table to database
dbWriteTable(con, "products", products)
## remove table
dbRemoveTable(con, "products")
## close connection
dbDisconnect(con)
## create connection to sqlite.db file
con <- dbConnect(SQLite(), "C:/Online Learning/DataRockie Bootcamp/DataRockie Bootcamp 10th/R Programming/data/chinook/chinook.db")
## list tables
dbListTables(con)
## list fields/ columns
dbListFields(con, "customers")
## get data from database tables
usa <- dbGetQuery(con, "
select
firstname,
lastname,
country,
email
from customers
where country = 'USA' ")
## create dataframe
products <- tribble(
~id, ~product_name,
1, "chocolate",
2, "pineapple",
3, "samsung galaxy s23"
)
## write table to database
dbWriteTable(con, "products", products)
## remove table
dbRemoveTable(con, "products")
## close connection
dbDisconnect(con)
usa
## connect to PostgreSQL server
## create connection to elephantsql.com after building a database
# these parameters below are used as connector
con <- dbConnect(
PostgreSQL(),
host = "arjuna.db.elephantsql.com",
dbname = "hcmsanst",
user = "hcmsanst",
password = "n9MIT1wNqy6HG5HsO-ypvf8SLD4VfMCh",
port = 5432
)
## db List Tables
dbListTables(con)
dbWriteTable(con, "products", products)
## get data
df <- dbGetQuery(con, "select id, product_name from products")
{
"name": "ham",
knitr::opts_chunk$set(echo = TRUE)
library(jsonlite)
list.files(pattern="*.json")
list.files(pattern="*.r")
cd
help
getwd()
/..
../..
setwd("C:\Online Learning\DataRockie Bootcamp\DataRockie Bootcamp 10th\R Programming\data)
getwd("C:/Online Learning/DataRockie Bootcamp/DataRockie Bootcamp 10th/R Programming/data)
e
gg
getwwd()
getwd()
break
../..
print("hello")
getwd()
)
getwd()
getwd(~/)
getwd(../data)
getwd(/R Programming/data)
getwd("/R Programming/data")
~/R Programming/data
## how to read a json file
fromJSON("../data/my_profile.json")
## how to read a json file
my_profile <- fromJSON("../data/my_profile.json")
my_profile
# library tidyverse
# data transformation => dplyr
# 1. select
# 2. filter
# 3. arrange
# 4. mutate => create new column
# 5. summarise
carnames <- rownames(mtcars)
mtcars <- rownames_to_column(mtcars, "model")
library(tidyverse)
library(RSQLite)
library(glue)
library(RPostgreSQL)
library(lubridate)
library(sqldf)
library(jsonlite)
# library tidyverse
# data transformation => dplyr
# 1. select
# 2. filter
# 3. arrange
# 4. mutate => create new column
# 5. summarise
carnames <- rownames(mtcars)
mtcars <- rownames_to_column(mtcars, "model")
# library tidyverse
# data transformation => dplyr
# 1. select
# 2. filter
# 3. arrange
# 4. mutate => create new column
# 5. summarise
carnames <- rownames(mtcars)
view(mtcars)
# pipeline
select(mtcars, mpg, hp, wt)
m2 <- mtcars %>%
select(mpg, hp, wt) %>%
filter(hp > 200) %>%
arrange(mpg) %>%
head()
head(arrange(filter(select(mtcars, mpg, hp, wt), hp > 200), mpg))
# filter am == 0
# grep can return character value and normally return the index of said value
# but grepl() will always return logic value
mtcars %>%
select(model, mpg, hp, wt, am) %>%
filter(am == 0 & grepl("^M", model)) %>%
arrange(am, desc(hp))
m3 <- mtcars %>%
select(model, mpg, hp, wt, am) %>%
filter(between(hp, 100, 200)) %>%
arrange(am, desc(hp))
# write csv file
write_csv(m3, "result.csv")
# mutate to create new columns
mtcars %>%
filter(mpg >= 20) %>%
select(model, mpg, hp, wt, am) %>%
mutate(new_col = "Data Rockie",
hp_halve = hp/2,
## =IF(am==0,"auto", "manual")
am_label = if_else(am==0,"auto", "manual"))
# summarise, summarize
# aggregate function in SQL
m4 <- mtcars %>%
mutate(am = if_else(am==0, "auto", "manual")) %>%
group_by(am) %>%
summarise(avg_mpg = mean(mpg),
med_mpg = median(mpg),
sum_mpg = sum(mpg),
max_mpg = max(mpg),
max_hp = max(hp),
min_hp = min(hp),
# spread
n = n(),
# var_hp = var(hp),
# sd_hp = sd(hp)
)
write_csv(m4, "sum_m4.csv")
## join in R
left_join(band_members, band_instruments, by = "name")
inner_join(band_members, band_instruments, by = "name")
full_join(band_members, band_instruments, by = "name")
m5 <- band_members %>%
select(member_name = name,
band_name = band) %>%
left_join(band_instruments,
by = c("member_name" = "name"))
## random sampling
# pull() pull column values only in a vector
mtcars %>%
sample_n(5) %>%
pull(model)
mtcars %>%
# sample_frac(0.20) %>%
summarise(avg_hp = mean(hp))
## summary
## 100% => Analytics
## 20% => Statistics
## count
mtcars <- mtcars %>%
mutate(am = if_else(am==0,
"Auto",
"Manual"))
# library tidyverse
# data transformation => dplyr
# 1. select
# 2. filter
# 3. arrange
# 4. mutate => create new column
# 5. summarise
carnames <- rownames(mtcars)
view(mtcars)
# pipeline
select(mtcars, mpg, hp, wt)
m2 <- mtcars %>%
select(mpg, hp, wt) %>%
filter(hp > 200) %>%
arrange(mpg) %>%
head()
head(arrange(filter(select(mtcars, mpg, hp, wt), hp > 200), mpg))
# filter am == 0
# grep can return character value and normally return the index of said value
# but grepl() will always return logic value
mtcars %>%
select(model, mpg, hp, wt, am) %>%
filter(am == 0 & grepl("^M", model)) %>%
arrange(am, desc(hp))
m3 <- mtcars %>%
select(model, mpg, hp, wt, am) %>%
filter(between(hp, 100, 200)) %>%
arrange(am, desc(hp))
# write csv file
write_csv(m3, "result.csv")
# mutate to create new columns
mtcars %>%
filter(mpg >= 20) %>%
select(model, mpg, hp, wt, am) %>%
mutate(new_col = "Data Rockie",
hp_halve = hp/2,
## =IF(am==0,"auto", "manual")
am_label = if_else(am==0,"auto", "manual"))
# summarise, summarize
# aggregate function in SQL
m4 <- mtcars %>%
mutate(am = if_else(am==0, "auto", "manual")) %>%
group_by(am) %>%
summarise(avg_mpg = mean(mpg),
med_mpg = median(mpg),
sum_mpg = sum(mpg),
max_mpg = max(mpg),
max_hp = max(hp),
min_hp = min(hp),
# spread
n = n(),
# var_hp = var(hp),
# sd_hp = sd(hp)
)
write_csv(m4, "sum_m4.csv")
## join in R
left_join(band_members, band_instruments, by = "name")
inner_join(band_members, band_instruments, by = "name")
full_join(band_members, band_instruments, by = "name")
m5 <- band_members %>%
select(member_name = name,
band_name = band) %>%
left_join(band_instruments,
by = c("member_name" = "name"))
## random sampling
# pull() pull column values only in a vector
mtcars %>%
sample_n(5) %>%
pull(model)
mtcars %>%
# sample_frac(0.20) %>%
summarise(avg_hp = mean(hp))
## summary
## 100% => Analytics
## 20% => Statistics
## count
mtcars <- mtcars %>%
mutate(am = if_else(am==0,
"Auto",
"Manual"))
ggplot(data = mtcars,
mapping = aes(x = mpg)) +
geom_histogram(bins=8)
library(tidyverse)
library(ggthemes)
ggplot(data = mtcars,
mapping = aes(x = mpg)) +
geom_histogram(bins=8)
ggplot(diamonds,
aes(x=price)) +
geom_histogram()
ggplot(diamonds,
aes(x=price)) +
geom_density()
## DRY: Donot Repeat Yourself
base <- ggplot(diamonds, aes(x=price))
p1 <- base + geom_histogram()
p2 <- base + geom_density()
## Boxplot
ggplot(diamonds, aes(x=price)) +
geom_boxplot()
## one variable + discrete (factor)
ggplot(diamonds, aes(cut)) +
geom_bar()
diamonds %>%
count(cut) %>%
ggplot(data = ., mapping=aes(x=cut, y=n)) +
geom_col()
set.seed(99)
ggplot(diamonds %>% sample_n(500),
# mapping
mapping = aes(x=carat, y=price,
color=cut)) +
# setting
geom_point(alpha=0.4, size=2) +
labs(
title="My first scatter plot",
subtitle="Cool ggplot2",
caption="Data: diamonds in Africa",
y = "Price in USD",
x = "Carat Diamonds"
) +
theme_minimal()
qplot(x = carat, data = diamonds, geom="density")
qplot(x = carat, data = diamonds, geom="histogram")
qplot(cut, data = diamonds, geom="bar")
## layers in ggplot2
base <- ggplot(diamonds %>%
sample_n(1000) %>%
filter(carat <= 2.8),
aes(x=carat, y=price))
p3 <- base +
theme_minimal() +
geom_point(alpha=0.7, color="#d2e80e") +
geom_smooth(method="loess", se=TRUE)
## bar plot
ggplot(diamonds, aes(cut, fill=clarity)) +
geom_bar(position="fill") +
theme_minimal()
## How to change color?
ggplot(diamonds, aes(cut, fill=cut)) +
geom_bar() +
theme_minimal() +
scale_fill_brewer(palette = "Accent")
## heat map color scale
ggplot(diamonds %>%
sample_frac(0.1), aes(carat, price, color=price)) +
geom_point(alpha=0.3) +
theme_minimal() +
scale_color_gradient(low = "gold", high = "purple")
ggplot(diamonds %>%
sample_frac(0.2), aes(carat,price)) +
geom_point(alpha=0.2, size=2, color="red") +
geom_smooth(method="lm", color="black") +
theme_minimal() +
facet_grid(~ cut)
m1 <- mtcars %>% filter(mpg > 30)
m2 <- mtcars %>% filter(mpg <= 20)
ggplot() +
theme_minimal() +
geom_point(data=m1, aes(wt, mpg), color="blue") +
geom_point(data=m2, aes(wt, mpg), color="red")
## bin2D
ggplot(diamonds, aes(carat, price)) +
geom_bin2d(bins=50)
library(patchwork)
p1 <- qplot(hwy, data=mpg, geom="density")
p2 <- qplot(cty, data=mpg, geom="histogram")
p3 <- qplot(cty, hwy, data=mpg, geom="point")
p4 <- qplot(cty, hwy, data=mpg, geom="smooth")
(p1 + p2 + p3) / p4
p1 / (p2 + p3 + p4)
View(my_profile)
