---
title: "Sprint 06 - STAT101 / Intro to Statistics"
author: "Sutiwas"
date: "2024-08-06"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Correlation

```{r correlation}
## correlation
cor(mtcars$mpg, mtcars$hp)
cor(mtcars$mpg, mtcars$wt)

plot(mtcars$hp, mtcars$mpg, pch=16)
plot(mtcars$wt, mtcars$mpg, pch=16)
plot(mtcars$wt, mtcars$hp, pch=16)

cor(mtcars[, c("mpg", "wt", "hp")])

## dplyr (tidyverse)
library(tidyverse)
corMAT <- mtcars %>%
  select(mpg, wt, hp) %>%
  cor()

cor.test(mtcars$hp, mtcars$mpg)

```

## Regression

```{r regression}
## mpg = f(hp)
lmFIT <- lm(mpg ~ hp, data = mtcars)

summary(lmFIT)

## predicction 1 veh
lmFIT$coefficients[[1]] + lmFIT$coefficients[[2]]*200

new_cars <- data.frame(
  hp = c(250, 220, 400, 450, 350)
)

## predict
new_cars$mpg_predict <- predict(lmFIT, newdata = new_cars)
new_cars$hp_predict < NULL

summary(mtcars$hp)
```

## RMSE

```{r, Root Mean Squared RMSE}
head(mtcars)

## Multiple Linear Regression
## mpg = intercept + b0*hp + b1*wt + b2*am
lmFIT2 <- lm(mpg ~ hp + wt + am, data = mtcars)
coef <- coef(lmFIT2)

coef[[1]] + coef[[2]]*200 + coef[[3]]*3.5 + coef[[4]]*1

## Build Full Model
lmFULL <- lm(mpg ~ ., data = mtcars)
mtcars$pred <- predict(lmFULL)

head(mtcars)

## RMSE
error <- (mtcars$mpg - mtcars$pred)**2
rmse <- sqrt(mean(error))
```

## Split Data =\> Train Model

```{r Split Data & Train Model}
## Split Data
set.seed(42)
n <- nrow(mtcars)
id <- sample(1:n, size = 0.8*n)
train_data <- mtcars[id, ]
test_data <- mtcars[-id, ]

## Train Model
model1 <- lm(mpg ~ hp + wt + am + disp, data = train_data)
p_train <- predict(model1)
error_train <- train_data$mpg - p_train
(rmse_train <- sqrt( mean( error_train**2  ) ))

## Test Model
p_test <- predict(model1, newdata=test_data)
error_test <- test_data$mpg - p_test
(rmse_test <- sqrt( mean( error_test**2  ) ))

## Print results
cat("RMSE TRAIN:", rmse_train,
    "\nRMSE_TEST:", rmse_test) ## Overfitting Problem
```

## Logistic Regression

```{r Logistic Regression}
## Logistic Regression
library(dplyr)

mtcars %>% head()

str(mtcars)

## Convert am to factorized string
mtcars$am <- factor(mtcars$am,
                     levels = c(0, 1),
                     labels = c("Auto", "Manual"))

class(mtcars$am)
table(mtcars$am)

## Split Data
set.seed(42)
n <- nrow(mtcars)
id <- sample(1:n, size = 0.8*n)
train_data <- mtcars[id, ]
test_data <- mtcars[-id, ]

## train model
logitModel <- glm(am ~ mpg, data = train_data, family = "binomial")
p_TrainLogit <- predict(logitModel, type = "response") ## probability
train_data$pred <- if_else(p_TrainLogit >= 0.5, "Manual", "Auto")
mean(train_data$am == train_data$pred)

## test model
p_TestLogit <- predict(logitModel, newdata = test_data, 
                       type = "response") ## probability
test_data$pred <- if_else(p_TestLogit >= 0.5, 
                           "Manual", "Auto")
mean(test_data$am == test_data$pred)

```
